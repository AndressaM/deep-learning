\input{../header.tex}

\subtitle{Perceptron}

\begin{document}

\frame{\titlepage}

%\begin{frame}
%\frametitle{Summary}
%{\tableofcontents}
%\end{frame}

\begin{frame}{Motivation}
\begin{figure}[!]
\centering
\includegraphics[width=.7\textwidth]{ml-com-perceptron.png}
\end{figure}
\footnote{\href{https://www.youtube.com/watch?v=-C07ansuc-8}{Aprendizagem de mÃ¡quina com o Perceptron.}}
\end{frame}


\begin{frame}{Motivation}
\begin{figure}[!]
\centering
\includegraphics[width=.7\textwidth]{perceptrong}
\end{figure}
\footnote{\href{https://github.com/tfvieira/deep-learning/blob/main/src/simple_perceptron/simple_perceptron.py}{Simple perceptron example using NumPy}}
\end{frame}




\begin{frame}
\frametitle{Binary Classification and Linear Regression Problems}
\begin{itemize}
\item In the binary classification problem, each training pair $(\overline{X}, y)$ contains feature variables $\overline{X}=(x_1, \ldots x_d)$, and  label
$y$  drawn from $\{ -1, +1 \}$.
\begin{itemize}
\item Example: Feature variables might be frequencies of words in an
email, and the class variable might be an indicator of spam.
\item Given labeled emails,  recognize incoming spam.
\end{itemize}
\item In linear regression, the {\em dependent} variable $y$ is real-valued.
\begin{itemize}
\item Feature variables are frequencies of words in a Web page,
and the  dependent variable is a prediction of the number of
accesses in a fixed period.
\end{itemize}
\item Perceptron is designed for the binary setting.
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{The Perceptron: Earliest Historical Architecture}
\begin{center}
\includegraphics[scale=0.4]{neurala.eps}
\end{center}
\begin{itemize}
\item The  $d$ nodes in the input layer only transmit the $d$
features $\overline{X}=[x_1 \ldots x_d]$ without performing any
computation.
\item  Output
node   multiplies input with  weights $\overline{W}=[w_1 \ldots
w_d]$ on incoming edges, aggregates them, and applies  {\em sign
activation}:
\begin{equation*}
\hat{y}= \mbox{sign}\{ \overline{W}\cdot \overline{X} \} =
\mbox{sign}\{ \sum_{j=1}^d w_j x_j \} \label{1nobias}
\end{equation*}
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{What is the Perceptron Doing?}
\begin{itemize}
\item Tries to find a {\em linear separator} $\overline{W}\cdot \overline{X}=0$ between the two
classes. \item  Ideally, all positive instances ($y=1$) should be on
the side of the separator satisfying $\overline{W} \cdot
\overline{X}>0$.
 \item  All negative  instances ($y=-1$) should be on the
side of the separator satisfying $\overline{W} \cdot
\overline{X}<0$.
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Bias Neurons}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
\includegraphics[scale=0.4]{neuralbiasa.eps}
\end{center}
\begin{itemize}
\item  In many settings (e.g., skewed class distribution) we need an
invariant part of the prediction with bias variable $b$:
\begin{equation*}
\hat{y}= \mbox{sign}\{ \overline{W}\cdot \overline{X} +b \} =
\mbox{sign}\{ \sum_{j=1}^d w_j x_j  + b  \} = \mbox{sign}\{
\sum_{j=1}^{d+1} w_j x_j    \}
\end{equation*}
\item On setting $w_{d+1}=b$ and $x_{d+1}$ as the input from the
bias neuron, it makes little difference to learning procedures
$\Rightarrow$ Often implicit in architectural diagrams
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Training a Perceptron}
\begin{itemize}
\item Go through the input-output pairs $(\overline{X}, y)$ one by one and make
updates, if predicted value $\hat{y}$ is different from observed
value $y$ $\Rightarrow$ Biological readjustment of synaptic weights.
\begin{eqnarray*}
& \overline{W}  \Leftarrow  \overline{W} +
\alpha \underbrace{(y - \hat{y})}_{\mbox{Error}} \overline{X}\\
& \overline{W}  \Leftarrow  \overline{W} + (2 \alpha)  y
\overline{X} \ \mbox{[For misclassified instances $y -\hat{y}= 2y$]}
\end{eqnarray*}
\item Parameter $\alpha$ is the learning rate $\Rightarrow$ Turns
out to be irrelevant in the special case of the perceptron
\item One cycle through the entire training data set is referred to
as an {\em epoch} $\Rightarrow$ Multiple epochs required
\item How did we derive these updates?
\end{itemize}
\end{frame}




\begin{frame}
\frametitle{What Objective Function is the Perceptron Optimizing?}
\begin{itemize}
\item At the time, the perceptron was proposed, the notion of loss
function was not popular $\Rightarrow$ Updates were heuristic

\item  Perceptron optimizes the perceptron criterion for $i$th training instance:
\begin{equation*}
 L_i= \mbox{max} \{ -y_i (\overline{W}\cdot \overline{X_i}), 0 \}
\end{equation*}
\begin{itemize}
\item Loss function tells us how far we are from a desired solution
$\Rightarrow$ Perceptron criterion is  0 when $\overline{W} \cdot
\overline{X_i}$ has same sign as $y_i$.
\end{itemize}
\item  Perceptron updates use  {\em stochastic gradient descent} to optimize the loss function and reach
the desired outcome.
\begin{itemize}
\item Updates are equivalent to $\overline{W} \Leftarrow  \overline{W}
- \alpha \left( \frac{\partial L_i}{\partial w_1} \ldots
\frac{\partial L_i}{\partial w_d} \right)$ \end{itemize}
\end{itemize}
\end{frame}


%\begin{frame}
%\frametitle{Perceptron vs Linear SVMs}
%\begin{itemize}
%\item Perceptron criterion
% is a shifted version of hinge-loss in SVM:
%\begin{equation*}
% L^{svm}_i = \mbox{max} \{ 1-y_i (\overline{W}\cdot \overline{X_i}), 0 \}
%\end{equation*}
%\begin{itemize}
%\item  The pre-condition for updates in perceptron and SVMs is different: \end{itemize}
%\begin{itemize}
%\item In a perceptron, we update when a misclassification occurs: $-y_i (\overline{W}\cdot
%\overline{X_i})>0$
%\item In a linear SVM, we update when a misclassification occurs or a classification is ``barely correct'': $1-y_i (\overline{W}\cdot
%\overline{X_i})>0$
%\end{itemize}
%\item Otherwise, {\em primal} updates of linear SVM are {\em identical} to perceptron: $$\overline{W}  \Leftarrow  \overline{W} +  \alpha  y
%\overline{X}$$
%\end{itemize}
%\end{frame}
%
%
%
%\begin{frame}
%\frametitle{Perceptron vs Linear SVMs}
%\begin{center}
%\includegraphics[scale=0.35]{compare.eps}
%\end{center}
%\begin{itemize}
%\item The more rigorous condition for the update in a linear SVM
%ensures that points near the decision boundary {\em generalize}
%better to the test data.
%\end{itemize}
%\end{frame}


\begin{frame}
\frametitle{Where does the Perceptron Fail?}
\begin{center}
\includegraphics[scale=0.4]{separable.eps}
\end{center}
\begin{itemize}
\item The perceptron fails at similar problems as a linear SVM
\begin{itemize}
\item {\bf Classical solution:} Feature engineering with
Radial Basis Function network $\Rightarrow$ Similar to kernel SVM
and good for noisy data
\item {\bf Deep learning solution:} Multilayer networks with
nonlinear activations $\Rightarrow$ Good for data with a lot of
structure
\end{itemize}
\end{itemize}
\end{frame}




\begin{frame}
\frametitle{Historical Origins}
\begin{itemize}
\item The first  model of a computational unit was the {\em
perceptron} (1958).
\begin{itemize}
\item Was roughly inspired by the biological model of a neuron.
\item Was implemented using a large piece of hardware.
\item Generated great excitement but failed to live up to inflated expectations.
\end{itemize}
\item Was not any more powerful than a simple linear model that can
be implemented in a  few lines of code today.
\end{itemize}
\end{frame}


\input{../lastframe.tex}


\end{document}
